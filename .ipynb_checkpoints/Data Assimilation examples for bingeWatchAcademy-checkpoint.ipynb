{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Assimilation examples used during Bingewatch Academy\n",
    "## Bingewatch Academy\n",
    "In my Bingewatch Academy talk I explored the question: \"Why is Daredevil better at predicting events than normal humans?\" I explained how data assimilation is used in weather forecasting to contiously combine observations and model predictions to get the best possible forecast of the future. In this notebook I will generate the figures that were used in my presentation. \n",
    "\n",
    "## Data assimilation\n",
    "Data assimilation is the science of combining observational data and knowledge of system behavior to get an optimal estimation, including an estimation of the uncertainty in your estimation, of a systems past, current and/or future states. There are many different data asismilation variations: some focussing on a specific family of systems, some on specific use cases. In this example the data assimilation method that I use is the Ensemble Kalman Filter. The 'system', or 'model' that I use is the Lorenz-96 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## the Lorenz 96 model\n",
    "The Lorenz 96 model <cite data-cite=\"2916206/TVEEWNWX\"></cite> is a typical chaotic dynamical sytem that is often used as a benchmark model in data assimilation studies. It was desigende by Lorenz as a toy-model for aAtmospheric circulation. It is defined for $i=1,...,N$ by\n",
    "\\begin{equation}\n",
    "\\frac{dx_{i}}{dt}=\\left(x_{i+1} - x_{i-2}\\right)x_{i-1} - x_{i} + F\n",
    "\\end{equation}\n",
    "where i is cyclical, ie. $x_{0}=x_{N}$ and $x_{-1} = x_{N-1}$. $F$ is an external force acting on the system. A value of $F=8$ is known to create chaotic bahavior and is often used. The dimension $N$ can be freely chosen and is typical $40$, but for testing very high dimension systems, higher values can be used. The Lorenz 96 model is a typical chaotic model where, although, the model is deterministic, slight variations in the input state will over time result in complete different states.\n",
    "\n",
    "## Numerical implementation of the Lorenz 96 model\n",
    "A fourth order Runga Kutta scheme is used to implement the Lorenz 96 model. Writing the entire state-vector as $\\vec{x}$ and using $f\\left(\\vec{x}\\right)$ as the right hand side of the model, ie:\n",
    "\\begin{eqnarray}\n",
    "f\\left(x_{i}\\right) = \\left(x_{i+1} - x_{i-2}\\right)x_{i-1} - x_{i} + F\n",
    "\\\\\n",
    "f\\left(\\vec{x}\\right) = \\left\\{f\\left(x_{1}\\right),...,f\\left(x_{N}\\right)\\right\\}\n",
    "\\end{eqnarray}\n",
    "the implementation is given by:\n",
    "\\begin{eqnarray}\n",
    "\\vec{k}_{1}=f\\left(\\vec{x}\\left(t\\right)\\right)\n",
    "\\\\\n",
    "\\vec{k}_{2}=f\\left(\\vec{x}\\left(t\\right) + \\frac{1}{2}\\vec{k}_{1}\\Delta t\\right)\n",
    "\\\\\n",
    "\\vec{k}_{3}=f\\left(\\vec{x}\\left(t\\right) + \\frac{1}{2}\\vec{k}_{2}\\Delta t\\right)\n",
    "\\\\\n",
    "\\vec{k}_{4}=f\\left(\\vec{x}\\left(t\\right) + \\vec{k}_{3}\\Delta t\\right)\n",
    "\\end{eqnarray}\n",
    "and finally\n",
    "\\begin{equation}\n",
    "\\vec{x}\\left(t + \\Delta t\\right) = \\vec{x}\\left(t\\right) + \\frac{1}{6}\\left(\\vec{k}_{1} + 2\\vec{k}_{2} + 2 \\vec{k}_{3} + \\vec{k}_{4}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "## The Basic Model Interface (BMI)\n",
    "The basic model interface allows communicating with models in a generic fashion. It requires a few standard methods to be available such as 'initialize()' and 'update()'. Methods that are not relevant for the model need still be implemented, but can simply raise a one line exception. See <cite data-cite=\"2916206/VXTQPCA7\"></cite> for more information. Implementing the BMI allows easy interaction with the model. The cells below initiate one instance of the model. For reasons that will become clear we will call this instance \"truthModel\".\n",
    "\n",
    "BMI models are typically initialized with a settings-file. This is overkill here, but for completeness, we generate the settings-file first and than pass it to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Kalman Filter example using Lorenz-96 model and BMI\n",
    "The Ensemble Kalman Filter (EnKF) is a variant on the Kalman Filter used when dealing with models for which it is hard to define a tangiant model. Data Assimilation methods, including all variants of the Kalman Filter Family, set to provide the (mathimatically) optimal estimation of the true state of a system, given that a (often phyiscal/physially based) model is available that can project the current state of the model into the future and that at the same time observations are available that measure (parts of) the state, either directly or indirectly.\n",
    "\n",
    "A mathematical overview of the EnKF is given in <cite data-cite=\"2916206/GVM9N4GZ\"></cite>. This notebook is intended as an introduction on how to do data assimilation within the eWaterCycle framework, with models that communicate through BMI. It is not intended as an indepth explenation of the EnKF. \n",
    "\n",
    "## data assimilation jargon\n",
    "The following terms are often used in data assimilation:\n",
    "\n",
    "- **ensemble** is a collection of model-instances. Often these are multiple instances of the same model where the spread in the model state represents the uncertainty in our knowledge of that model state.\n",
    "- **model** a mathematical and/or computer code represenation of how the state of the system evolves in time.  \n",
    "- **observation** a measurement (or set of measurements, including images)that relate to (part of) the state of the system\n",
    "- **observation model** a mathematical and/or computer code representation of how the state relates to the observations. Often donated by $\\mathbf{H}$.\n",
    "- **forecast** The forecasted state using the model and a previous state\n",
    "- **analyses** The best estimate of the state using both a forecast and an observation. The analyses (or analyses-ensemble) is the output of a data assimilation method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries and settings\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import io\n",
    "import math\n",
    "\n",
    "import BMILorenz\n",
    "import EnKF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## settings\n",
    "The settings for this experiment are split between settings for the model, for the observations and for the data assimilation method and finally for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model\n",
    "\n",
    "J = 40 #dimension of Lorenz-96 Model\n",
    "commonStartState = [0 for i in range(J)] #start-vector\n",
    "commonStartState[5]=0.01\n",
    "\n",
    "#settings data in dict for export to YAML file\n",
    "settings = {'J': J,\n",
    "            'F': 8.0,\n",
    "            'startTime': 0.0,\n",
    "            'endTime': 10.0,\n",
    "            'dt':1e-3,\n",
    "            'startState': commonStartState}\n",
    "\n",
    "\n",
    "\n",
    "##Observations\n",
    "observationSigma = [0.05,0.5]          #standard deviation of the observations. I'm running two different versions!\n",
    "obsVector = range(math.floor(J/2))  #only observe half of the state\n",
    "obsSize = len(obsVector);           #size of the observations vector\n",
    "def H(state):                       #the \"observation model\" that links model-space to observation-space\n",
    "    return state[obsVector]\n",
    "\n",
    "\n",
    "##Ensemble Kalman Filter\n",
    "N = 100                             #numeber of ensemble members, needs to be higher than dimension of the\n",
    "                                    # model for stability, since no inflation is implemented.\n",
    "\n",
    "## Experiment\n",
    "spinUpTime = 3                      #time that the ensemble is run before data assimilation starts to \n",
    "updateInterval = 1                  #how often is the ensemble updated with observations\n",
    "\n",
    "plotState = 5                       #which state of the model (both truth and ensemble) to plot\n",
    "obsPlotState = 5                    #which state of the observations to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write YAML setting file for BMI model\n",
    "with io.open('settings.yaml', 'w', encoding='utf8') as outfile:\n",
    "    yaml.safe_dump(settings, outfile, default_flow_style=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with two empty ensembles. create one ensemble for the \"high observational error\" case and one for low errors.\n",
    "ensembleLow = []\n",
    "ensembleHigh = []\n",
    "\n",
    "\n",
    "#create and initialize an instance of the BMILorenz class\n",
    "truthModel = BMILorenz.BMILorenz ()\n",
    "truthModel.initialize('settings.yaml')\n",
    "\n",
    "output = pd.DataFrame(columns = ['truth','observation'])\n",
    "\n",
    "for n in range (N):\n",
    "    #add an ensemble methods\n",
    "    ensembleLow.append(BMILorenz.BMILorenz ())\n",
    "    ensembleLow[n].initialize('settings.yaml')\n",
    "    ensembleLow[n].set_value_at_indices('state',5,ensembleLow[n].get_value_at_indices('state',5) + np.random.randn(1)*0.01)\n",
    "    ensembleHigh.append(BMILorenz.BMILorenz ())\n",
    "    ensembleHigh[n].initialize('settings.yaml')\n",
    "    ensembleHigh[n].set_value_at_indices('state',5,ensembleHigh[n].get_value_at_indices('state',5) + np.random.randn(1)*0.01)\n",
    "    \n",
    "    #also add a column to the output dataframe to store the output\n",
    "    output['ensembleLow' + str(n)]= np.nan\n",
    "    output['ensembleHigh' + str(n)]= np.nan\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spin up the Ensemble. \n",
    "\n",
    "while truthModel.get_current_time()< spinUpTime:\n",
    "    \n",
    "    truthModel.update()\n",
    "    output.loc[truthModel.get_current_time(),'truth'] = truthModel.get_value_at_indices('state',plotState)\n",
    "    \n",
    "    #observationLow = truthModel.get_value('state') + observationSigma[0] * np.random.randn(J)\n",
    "    #output.at[truthModel.get_current_time(),'observationLow'] = observationLow[plotState]\n",
    "\n",
    "    #observationHigh = truthModel.get_value('state') + observationSigma[1] * np.random.randn(J)\n",
    "    #output.at[truthModel.get_current_time(),'observationJigh'] = observationHigh[plotState]\n",
    "    \n",
    "    #loop through the ensemble members and store the state after each update\n",
    "    for n in range (N):\n",
    "        ensembleLow[n].update()\n",
    "        output.at[ensembleLow[n].get_current_time(),'ensembleLow' + str(n)] = ensembleLow[n].get_value_at_indices('state',plotState)\n",
    "        ensembleHigh[n].update()\n",
    "        output.at[ensembleHigh[n].get_current_time(),'ensembleHigh' + str(n)] = ensembleHigh[n].get_value_at_indices('state',plotState)\n",
    "        \n",
    "updateTime = spinUpTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run \n",
    "\n",
    "foreCastEnsembleLow = np.zeros([J,N])\n",
    "foreCastEnsembleHigh = np.zeros([J,N])\n",
    "observationEnsembleLow = np.zeros([obsSize,N])\n",
    "observationEnsembleHigh = np.zeros([obsSize,N])\n",
    "\n",
    "while truthModel.get_current_time()<truthModel.get_end_time():\n",
    "    truthModel.update()\n",
    "    output.loc[truthModel.get_current_time(),'truth'] = truthModel.get_value_at_indices('state',plotState)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #loop through the ensemble members and store the state after each update\n",
    "    for n in range (N):\n",
    "        ensembleLow[n].update()\n",
    "        ensembleHigh[n].update()\n",
    "        #observationEnsemble[:,n] = observation + observationSigma*np.random.randn(obsSize)\n",
    "        output.at[ensembleLow[n].get_current_time(),'ensembleLow' + str(n)] = ensembleLow[n].get_value_at_indices('state',plotState)\n",
    "        output.at[ensembleHigh[n].get_current_time(),'ensembleHigh' + str(n)] = ensembleHigh[n].get_value_at_indices('state',plotState)\n",
    "        \n",
    "    #TODO update ensemble on bases of observation\n",
    "    if truthModel.get_current_time() > updateTime:\n",
    "        \n",
    "        observationLow = H(truthModel.get_value('state')) + observationSigma[0] * np.random.randn(obsSize)\n",
    "        output.at[truthModel.get_current_time(),'observationLow'] = observationLow[plotState]\n",
    "        \n",
    "        observationHigh = H(truthModel.get_value('state')) + observationSigma[1] * np.random.randn(obsSize)\n",
    "        output.at[truthModel.get_current_time(),'observationHigh'] = observationHigh[plotState]\n",
    "\n",
    "        for n in range (N):\n",
    "            observationEnsembleHigh[:,n] = observationHigh + observationSigma[1]*np.random.randn(obsSize)\n",
    "            observationEnsembleLow[:,n] = observationLow + observationSigma[0]*np.random.randn(obsSize)\n",
    "            foreCastEnsembleLow[:,n] = ensembleLow[n].get_value('state')\n",
    "            foreCastEnsembleHigh[:,n] = ensembleHigh[n].get_value('state')\n",
    "        \n",
    "        analysesEnsembleLow = EnKF.EnKF(foreCastEnsembleLow,observationEnsembleLow,H)\n",
    "        np.clip(analysesEnsembleLow, -10, 20, out=analysesEnsembleLow)\n",
    "        for n in range (N):\n",
    "            ensembleLow[n].set_value('state',analysesEnsembleLow[:,n])\n",
    "\n",
    "        analysesEnsembleHigh = EnKF.EnKF(foreCastEnsembleHigh,observationEnsembleHigh,H)\n",
    "        np.clip(analysesEnsembleHigh, -10, 20, out=analysesEnsembleHigh)\n",
    "        for n in range (N):\n",
    "            ensembleHigh[n].set_value('state',analysesEnsembleHigh[:,n])\n",
    "        \n",
    "\n",
    "        \n",
    "        updateTime = updateTime + updateInterval\n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here come the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output.loc[output.index < 3,'truth'],'r')\n",
    "plt.xlim([0,6])\n",
    "plt.ylim([-10,15])\n",
    "plt.xlabel('time')\n",
    "plt.savefig('truth.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(output.loc[output.index < 3,output.columns.str.startswith('ensembleHigh')],'k')\n",
    "plt.plot(output.loc[output.index < 3,'truth'],'r')\n",
    "plt.xlim([0,6])\n",
    "plt.ylim([-10,15])\n",
    "plt.xlabel('time')\n",
    "plt.savefig('truthEnsemble.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output.loc[output.index < 4,output.columns.str.startswith('ensembleHigh')],'k')\n",
    "plt.plot(output.loc[output.index < 4,'observationHigh'],'r.',output.loc[output.index < 4,'observationHigh']+2*observationSigma[1],'r*',output.loc[output.index < 4,'observationHigh']-2*observationSigma[1],'r*')\n",
    "plt.plot(output.loc[output.index < 4,'truth'],'r')\n",
    "plt.xlim([0,6])\n",
    "plt.ylim([-10,15])\n",
    "plt.xlabel('time')\n",
    "plt.savefig('EnKFHigh1step.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output.loc[output.index < 6,output.columns.str.startswith('ensembleHigh')],'k')\n",
    "plt.plot(output.loc[output.index < 6,'observationHigh'],'r.',output.loc[:,'observationHigh']+2*observationSigma[1],'r*',output.loc[:,'observationHigh']-2*observationSigma[1],'r*')\n",
    "plt.plot(output.loc[output.index < 6,'truth'],'r')\n",
    "plt.xlim([0,6])\n",
    "plt.ylim([-10,15])\n",
    "plt.xlabel('time')\n",
    "plt.savefig('EnKFHigh.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output.loc[output.index < 6,output.columns.str.startswith('ensembleLow')],'k')\n",
    "plt.plot(output.loc[output.index < 6,'observationLow'],'r.',output.loc[:,'observationLow']+2*observationSigma[0],'r*',output.loc[:,'observationLow']-2*observationSigma[0],'r*')\n",
    "plt.plot(output.loc[output.index < 6,'truth'],'r')\n",
    "plt.xlim([0,6])\n",
    "plt.ylim([-10,15])\n",
    "plt.xlabel('time')\n",
    "plt.savefig('EnKFLow.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output.loc[output.index < 6,output.columns.str.startswith('ensembleLow1')],'k')\n",
    "plt.plot(output.loc[output.index < 6,'observationLow'],'r.',output.loc[:,'observationLow']+2*observationSigma[0],'r*',output.loc[:,'observationLow']-2*observationSigma[0],'r*')\n",
    "plt.plot(output.loc[output.index < 6,'truth'],'r')\n",
    "plt.xlim([0,6])\n",
    "plt.ylim([-10,15])\n",
    "plt.xlabel('time')\n",
    "plt.savefig('EnKFLow10ens.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div>"
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "2916206/GVM9N4GZ": {
     "DOI": "10.1007/s10236-003-0036-9",
     "URL": "http://link.springer.com/article/10.1007/s10236-003-0036-9",
     "abstract": "The purpose of this paper is to provide a comprehensive presentation and interpretation of the Ensemble Kalman Filter (EnKF) and its numerical implementation. The EnKF has a large user group, and numerous publications have discussed applications and theoretical aspects of it. This paper reviews the important results from these studies and also presents new ideas and alternative interpretations which further explain the success of the EnKF. In addition to providing the theoretical framework needed for using the EnKF, there is also a focus on the algorithmic formulation and optimal numerical implementation. A program listing is given for some of the key subroutines. The paper also touches upon specific issues such as the use of nonlinear measurements, in situ profiles of temperature and salinity, and data which are available with high frequency in time. An ensemble based optimal interpolation (EnOI) scheme is presented as a cost-effective approach which may serve as an alternative to the EnKF in some applications. A fairly extensive discussion is devoted to the use of time correlated model errors and the estimation of model bias.",
     "accessed": {
      "day": 15,
      "month": 6,
      "year": 2016
     },
     "author": [
      {
       "family": "Evensen",
       "given": "Geir"
      }
     ],
     "container-title": "Ocean Dynamics",
     "container-title-short": "Ocean Dynamics",
     "id": "2916206/GVM9N4GZ",
     "issue": "4",
     "issued": {
      "year": 2003
     },
     "journalAbbreviation": "Ocean Dynamics",
     "language": "en",
     "page": "343-367",
     "page-first": "343",
     "shortTitle": "The Ensemble Kalman Filter",
     "title": "The Ensemble Kalman Filter: theoretical formulation and practical implementation",
     "title-short": "The Ensemble Kalman Filter",
     "type": "article-journal",
     "volume": "53"
    },
    "2916206/TVEEWNWX": {
     "author": [
      {
       "family": "Lorenz",
       "given": "Edward N"
      }
     ],
     "container-title": "Proc. Seminar on predictability",
     "id": "2916206/TVEEWNWX",
     "issued": {
      "year": 1996
     },
     "note": "Citation Key: lorenz1996predictability \nbibtex*[number=1]",
     "title": "Predictability: A problem partly solved",
     "type": "paper-conference",
     "volume": "1"
    },
    "2916206/VXTQPCA7": {
     "DOI": "10.1016/j.cageo.2012.04.002",
     "URL": "http://www.sciencedirect.com/science/article/pii/S0098300412001252",
     "abstract": "Development of scientific modeling software increasingly requires the coupling of multiple, independently developed models. Component-based software engineering enables the integration of plug-and-play components, but significant additional challenges must be addressed in any specific domain in order to produce a usable development and simulation environment that also encourages contributions and adoption by entire communities. In this paper we describe the challenges in creating a coupling environment for Earth-surface process modeling and the innovative approach that we have developed to address them within the Community Surface Dynamics Modeling System.",
     "accessed": {
      "day": 20,
      "month": 6,
      "year": 2016
     },
     "author": [
      {
       "family": "Peckham",
       "given": "Scott D."
      },
      {
       "family": "Hutton",
       "given": "Eric W. H."
      },
      {
       "family": "Norris",
       "given": "Boyana"
      }
     ],
     "collection-title": "Modeling for Environmental Change",
     "container-title": "Computers & Geosciences",
     "container-title-short": "Computers & Geosciences",
     "id": "2916206/VXTQPCA7",
     "issued": {
      "month": 4,
      "year": 2013
     },
     "journalAbbreviation": "Computers & Geosciences",
     "page": "3-12",
     "page-first": "3",
     "shortTitle": "A component-based approach to integrated modeling in the geosciences",
     "title": "A component-based approach to integrated modeling in the geosciences: The design of CSDMS",
     "title-short": "A component-based approach to integrated modeling in the geosciences",
     "type": "article-journal",
     "volume": "53"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
