{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Assimilation in eWaterCycle using BMI\n",
    "## Ensemble Kalman Filter example using Lorenz-96 model\n",
    "The Ensemble Kalman Filter (EnKF) is a variant on the Kalman Filter when dealing with models for which it is hard to define a tangiant model. Data Assimilation methods, including all variants of the Kalman Filter Family, set to provide the (mathimatically) optimal estimation of the true state of a system, given that a (often phyiscal/physially based) model is available that can project the current state of the model into the future and that at the same time observations are available that measure (parts of) the state, either directly or indirectly.\n",
    "\n",
    "A mathematical overview of the EnKF is given in [cite Evensen]. This notebook is intended as an introduction on how to do data assimilation within the eWaterCycle framework, with models that communicate through BMI. It is not intended as an indepth explenation of the EnKF. \n",
    "\n",
    "## data assimilation jargon\n",
    "The following terms are often used in data assimilation:\n",
    "\n",
    "- **ensemble** is a collection of model-instances. Often these are multiple instances of the same model where the spread in the model state represents the uncertainty in our knowledge of that model state.\n",
    "- **model** a mathematical and/or computer code represenation of how the state of the system evolves in time.  \n",
    "- **observation** a measurement (or set of measurements, including images)that relate to (part of) the state of the system\n",
    "- **observation model** a mathematical and/or computer code representation of how the state relates to the observations. Often donated by $\\mathbf{H}$.\n",
    "- **forecast** The forecasted state using the model and a previous state\n",
    "- **analyses** The best estimate of the state using both a forecast and an observation. The analyses (or analyses-ensemble) is the output of a data assimilation method.\n",
    "\n",
    "In this notebook I will use a Lorenz-96 model that has been wrapped with BMI, see the 'Lorenz-96 model ensemble demonstration' notebook in this repository for an introduction into that model. I use the Ensemble Kalman Filter as data assimilation method, see [cite Evensen]. The focus of this notebook is to demonstrate how to do a data assimilation experiment where the model and the method are not part of the experiment code.\n",
    "\n",
    "The experiment I run is a comparison of the bias of the ensemble mean versus the truth and of the spread of the ensemble over time. The Truth is generated through a model instance classified as \"true\" and the ensemble starts as slight modifications of this truth, which after a spin-up period, significantly deviate from the truth. The observations are direct measurements of part of the state, with added measurement noise.\n",
    "\n",
    "The first cell loads all the needed dependencies. The final two are the model and the data assimilation method and are shared with this repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries and settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import io\n",
    "import math\n",
    "\n",
    "import BMILorenz\n",
    "import EnKF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [Ray](https://ray.readthedocs.io) to distribute models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-13 14:03:25,565\tINFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-08-13_14-03-25_565775_25322/logs.\n",
      "2019-08-13 14:03:25,693\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:27229 to respond...\n",
      "2019-08-13 14:03:25,806\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:52443 to respond...\n",
      "2019-08-13 14:03:25,810\tINFO services.py:809 -- Starting Redis shard with 3.36 GB max memory.\n",
      "2019-08-13 14:03:25,980\tINFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-08-13_14-03-25_565775_25322/logs.\n",
      "2019-08-13 14:03:25,982\tINFO services.py:1475 -- Starting the Plasma object store with 5.05 GB memory using /dev/shm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "View the dashboard at http://10.0.2.15:8080/?token=389cbebffea7b2dbcfbe231f94ef64fb485392d5831eaef2\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.0.2.15',\n",
       " 'redis_address': '10.0.2.15:27229',\n",
       " 'object_store_address': '/tmp/ray/session_2019-08-13_14-03-25_565775_25322/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-08-13_14-03-25_565775_25322/sockets/raylet',\n",
       " 'webui_url': 'http://10.0.2.15:8080/?token=389cbebffea7b2dbcfbe231f94ef64fb485392d5831eaef2',\n",
       " 'session_dir': '/tmp/ray/session_2019-08-13_14-03-25_565775_25322'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import cpu_count\n",
    "import ray\n",
    "ray.init(num_cpus=cpu_count(), include_webui=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## settings\n",
    "The settings for this experiment are split between settings for the model, for the observations and for the data assimilation method and finally for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model\n",
    "\n",
    "J = 40 #dimension of Lorenz-96 Model\n",
    "commonStartState = np.zeros(J) #start-vector\n",
    "commonStartState[5]=0.01\n",
    "\n",
    "#settings data in dict for export to YAML file\n",
    "settings = {'J': J,\n",
    "            'F': 8.0,\n",
    "            'startTime': 0.0,\n",
    "            'endTime': 10.0,\n",
    "            'dt':1e-3,\n",
    "            'startState': commonStartState}\n",
    "\n",
    "\n",
    "\n",
    "##Observations\n",
    "observationSigma = 0.05             #standard deviation of the observations\n",
    "obsVector = range(math.floor(J/2))  #only observe half of the state\n",
    "obsSize = len(obsVector);           #size of the observations vector\n",
    "def H(state):                       #the \"observation model\" that links model-space to observation-space\n",
    "    return state[obsVector]\n",
    "\n",
    "\n",
    "##Ensemble Kalman Filter\n",
    "N = 100                             #numeber of ensemble members, needs to be higher than dimension of the\n",
    "                                    # model for stability, since no inflation is implemented.\n",
    "    \n",
    "## Experiment\n",
    "spinUpTime = 3                      #time that the ensemble is run before data assimilation starts to \n",
    "updateInterval = 1                  #how often is the ensemble updated with observations\n",
    "\n",
    "plotState = 5                       #which state of the model (both truth and ensemble) to plot\n",
    "obsPlotState = 5                    #which state of the observations to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawl before running\n",
    "N = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write YAML setting file for BMI model\n",
    "with io.open('settings.yaml', 'w', encoding='utf8') as outfile:\n",
    "    yaml.dump(settings, outfile, default_flow_style=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-13 14:04:05,646\tERROR worker.py:1714 -- WARNING: 18 workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 107 ms, sys: 30 ms, total: 137 ms\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#start with  an empty ensemble\n",
    "ensemble = []\n",
    "\n",
    "\n",
    "#create and initialize an instance of the BMILorenz class\n",
    "truthModel = BMILorenz.BMILorenz ()\n",
    "truthModel.initialize('settings.yaml')\n",
    "\n",
    "output = pd.DataFrame(columns = ['truth','observation'])\n",
    "\n",
    "RayBMILorenz = ray.remote(BMILorenz.BMILorenz)\n",
    "\n",
    "ensemble = [RayBMILorenz.remote() for _ in range(N)]\n",
    "ray.get([e.initialize.remote('settings.yaml') for e in ensemble])\n",
    "initial_state = ray.get([e.get_value_at_indices.remote('state',5) for e in ensemble])\n",
    "ray.get([e.set_value_at_indices.remote('state',5, s + np.random.randn(1)*0.01) for e, s in zip(ensemble, initial_state)])\n",
    "for n in range (N):\n",
    "    #also add a column to the output dataframe to store the output\n",
    "    output['ensemble' + str(n)]= np.nan\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Seqential took CPU times: user 1min 47s, sys: 623 ms, total: 1min 47s Wall time: 1min 48s\n",
    "# Ray with cpu=6\n",
    "#spin up the Ensemble. \n",
    "\n",
    "while truthModel.get_current_time()< spinUpTime:\n",
    "    \n",
    "    truthModel.update()\n",
    "    output.loc[truthModel.get_current_time(),'truth'] = truthModel.get_value_at_indices('state',plotState)\n",
    "    \n",
    "    observation = truthModel.get_value('state') + observationSigma * np.random.randn(J)\n",
    "    output.at[truthModel.get_current_time(),'observation'] = observation[plotState]\n",
    "    \n",
    "    #loop through the ensemble members and store the state after each update\n",
    "    ray.get([e.update.remote() for e in ensemble])\n",
    "    for n in range (N):\n",
    "        output.at[ray.get(ensemble[n].get_current_time.remote()),'ensemble' + str(n)] = ray.get(ensemble[n].get_value_at_indices.remote('state',plotState))\n",
    "        \n",
    "    #TODO update observation on bases of observation\n",
    "    \n",
    "    #TODO track statistics metrics\n",
    "    \n",
    "updateTime = spinUpTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#run \n",
    "\n",
    "foreCastEnsemble = np.zeros([J,N])\n",
    "observationEnsemble = np.zeros([obsSize,N])\n",
    "\n",
    "while truthModel.get_current_time()<truthModel.get_end_time():\n",
    "    truthModel.update()\n",
    "    output.loc[truthModel.get_current_time(),'truth'] = truthModel.get_value_at_indices('state',plotState)\n",
    "    \n",
    "    observation = H(truthModel.get_value('state')) + observationSigma * np.random.randn(obsSize)\n",
    "    output.at[truthModel.get_current_time(),'observation'] = observation[plotState]\n",
    "    \n",
    "    \n",
    "\n",
    "    #loop through the ensemble members and store the state after each update\n",
    "    ray.get([e.update.remote() for e in ensemble])\n",
    "    for n in range (N):\n",
    "        foreCastEnsemble[:,n] = ray.get(ensemble[n].get_value.remote('state'))\n",
    "        observationEnsemble[:,n] = observation + observationSigma*np.random.randn(obsSize)\n",
    "        output.at[ray.get(ensemble[n].get_current_time.remote()),'ensemble' + str(n)] = ray.get(ensemble[n].get_value_at_indices.remote('state',plotState))\n",
    "        \n",
    "    #TODO update ensemble on bases of observation\n",
    "    if truthModel.get_current_time() > updateTime:\n",
    "        updateTime = updateTime + updateInterval\n",
    "        analysesEnsemble = EnKF.EnKF(foreCastEnsemble,observationEnsemble,H)\n",
    "        np.clip(analysesEnsemble, -10, 20, out=analysesEnsemble)\n",
    "\n",
    "        ray.get([e.set_value.remote('state', analysesEnsemble[:,n]) for n, e in enumerate(ensemble)])\n",
    "    \n",
    "    \n",
    "    #TODO track statistics metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output.loc[:,'ensemble0':],'k')\n",
    "plt.plot(output.loc[:,'observation'],'r')\n",
    "plt.plot(output.loc[:,'truth'],'g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
